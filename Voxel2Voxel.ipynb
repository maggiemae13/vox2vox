{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import v2v as v2v\n",
    "from Colormaps import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/maggiemae/Desktop/Current_Data/vim1_redo/'\n",
    "\n",
    "area_list= ['v1', 'v2', 'v3', 'v4', 'v3ab', 'LO', 'wm', 'air']\n",
    "roiNum = {'v1':1,'v2':2,'v3':3,'v4':6,'v3ab':4,'LO':7, 'wm':10 ,'air':20}\n",
    "lambda_list = np.logspace(1,6,num=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LOAD Data. Note S1 Repeated Trial Analysis has white matter/ noise betas included\n",
    "\n",
    "fn = data_folder + 'betas/Rank1GLM_Beta_Responses.mat'\n",
    "\n",
    "S1VoxelNanMaskRep = sio.loadmat(fn)['voxelNanMaskS1N'][0,:].astype('bool')\n",
    "S1VoxelNanMaskSing = sio.loadmat(fn)['voxelNanMaskS1'][0,:].astype('bool')\n",
    "\n",
    "S1TrainDataRep = sio.loadmat(fn)['dataTrnS1'][:,S1VoxelNanMaskRep]\n",
    "S1TestDataRep  = sio.loadmat(fn)['dataValS1'][:,S1VoxelNanMaskRep]\n",
    "\n",
    "S1TrainDataSing = sio.loadmat(fn)['dataTrnSingleS1'][:,S1VoxelNanMaskSing]\n",
    "S1TestDataSing  = sio.loadmat(fn)['dataValSingleS1'][:,S1VoxelNanMaskSing]\n",
    "\n",
    "S1RoiMaskRep = sio.loadmat(fn)['roiS1N'][0,S1VoxelNanMaskRep]\n",
    "S1RoiMaskSing= sio.loadmat(fn)['roiS1'][0,S1VoxelNanMaskSing]\n",
    "\n",
    "# ---------- #\n",
    "\n",
    "S2VoxelNanMask= sio.loadmat(fn)['voxelNanMaskS2'][0,:].astype('bool')\n",
    "\n",
    "S2TrainDataRep = sio.loadmat(fn)['dataTrnS2'][:,S2VoxelNanMask]\n",
    "S2TestDataRep  = sio.loadmat(fn)['dataValS2'][:,S2VoxelNanMask]\n",
    "\n",
    "S2TrainDataSing = sio.loadmat(fn)['dataTrnSingleS2'][:,S2VoxelNanMask]\n",
    "S2TestDataSing  = sio.loadmat(fn)['dataValSingleS2'][:,S2VoxelNanMask]\n",
    "\n",
    "S2RoiMask = sio.loadmat(fn)['roiS2'][0,S2VoxelNanMask]\n",
    "\n",
    "# Combine V3a & V3b and Both White Matter ROIs for S1\n",
    "\n",
    "S1RoiMaskRep[S1RoiMaskRep==5]=4\n",
    "S1RoiMaskSing[S1RoiMaskSing==5]=4\n",
    "\n",
    "S1RoiMaskRep[S1RoiMaskRep==12]=10\n",
    "S1RoiMaskSing[S1RoiMaskSing==12]=10\n",
    "\n",
    "S2RoiMask[S2RoiMask==5]=4\n",
    "S2RoiMask[S2RoiMask==12]=10\n",
    "\n",
    "if any([len(S1TrainDataRep)!=1750, len(S1TestDataRep)!=120,\n",
    "        len(S1TrainDataSing)!=3500, len(S1TestDataSing)!= 1560,\n",
    "        len(S2TrainDataRep)!=1750, len(S2TestDataRep)!=120,\n",
    "        len(S2TrainDataSing)!=3500, len(S2TestDataSing)!= 1560]):\n",
    "    print 'ERROR INCORRECT TRIAL NUMBERS FOR VIM1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 has 24353 total voxels. V1: 1294, V2: 2095, V3: 1814, V4: 1541, V3ab: 798, LO: 928, WM: 541, Air: 794\n",
      "Subject 2 has 21832 total voxels. V1: 1433, V2: 1890, V3: 1775, V4: 1022, V3ab: 1048, LO: 358\n"
     ]
    }
   ],
   "source": [
    "print 'Subject 1 has %d total voxels. V1: %d, V2: %d, V3: %d, V4: %d, V3ab: %d, LO: %d, WM: %d, Air: %d'%(\\\n",
    "        len(S1RoiMaskRep), (S1RoiMaskRep==1).sum(), (S1RoiMaskRep==2).sum(), (S1RoiMaskRep==3).sum(),\n",
    "        (S1RoiMaskRep==6).sum(), (S1RoiMaskRep==4).sum(), (S1RoiMaskRep==7).sum(), (S1RoiMaskRep==10).sum(),\n",
    "        (S1RoiMaskRep==20).sum())\n",
    "\n",
    "print 'Subject 2 has %d total voxels. V1: %d, V2: %d, V3: %d, V4: %d, V3ab: %d, LO: %d'%(\\\n",
    "        len(S2RoiMask), (S2RoiMask==1).sum(), (S2RoiMask==2).sum(), (S2RoiMask==3).sum(),\n",
    "        (S2RoiMask==6).sum(), (S2RoiMask==4).sum(), (S2RoiMask==7).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Trial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep at least WTs dataframe named seperately, will need later on for adjustments\n",
    "df_cc_S1_avg, df_wts_S1_avg, best_lambs_S1_avg = v2v.vox2vox(area_list, area_list, S1TrainDataRep, \n",
    "                                                                      S1TestDataRep, lambda_list, 'average', \n",
    "                                                                      .2, roiNum, S1RoiMaskRep)\n",
    "\n",
    "df_cc_S1_avg.to_pickle(data_folder + 'results/voxel2voxel/S1_avg_cc.pkl') \n",
    "df_wts_S1_avg.to_pickle(data_folder + 'results/voxel2voxel/S1_avg_wts.pkl')  \n",
    "best_lambs_S1_avg.to_pickle(data_folder + 'results/voxel2voxel/S1_avg_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], S2TrainDataRep, S2TestDataRep, lambda_list, \n",
    "                                        'average', .2, roiNum, S2RoiMask)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S2_avg_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S2_avg_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S2_avg_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matched Trial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6],area_list[:6],S1TrainDataSing,S1TestDataSing, lambda_list, \n",
    "                                        'average', .2, roiNum, S1RoiMaskSing)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_single_match_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_single_match_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_single_match_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6],area_list[:6],S2TrainDataSing,S2TestDataSing, lambda_list, \n",
    "                                        'average',.2, roiNum, S2RoiMask)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S2_single_match_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S2_single_match_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S2_single_match_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Trial Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next cell reformats the single trial data so that it can easily be used by the source code to match the correct trials with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTrialOrder = sio.loadmat(fn)['trnTrialOrderSingle'][0,:]\n",
    "tstTrialOrder = sio.loadmat(fn)['valTrialOrderSingle'][0,:]\n",
    "\n",
    "first_instance = [trainTrialOrder.tolist().index(i) for i in range(1750)]\n",
    "second_instance = np.ones(3500, dtype='bool')\n",
    "second_instance[first_instance]=0\n",
    "\n",
    "tstOrder = np.argsort(tstTrialOrder, kind='stable')\n",
    "\n",
    "S1TrainDataSingMix = np.zeros_like(S1TrainDataSing)\n",
    "S1TrainDataSingMix[:1750] = S1TrainDataSing[first_instance]\n",
    "S1TrainDataSingMix[1750:] = S1TrainDataSing[second_instance]\n",
    "\n",
    "S2TrainDataSingMix = np.zeros_like(S2TrainDataSing)\n",
    "S2TrainDataSingMix[:1750] = S2TrainDataSing[first_instance]\n",
    "S2TrainDataSingMix[1750:] = S2TrainDataSing[second_instance]\n",
    "\n",
    "S1TestDataSingMix = S1TrainDataSing[np.argsort(tstTrialOrder, kind='stable')]\n",
    "S2TestDataSingMix = S2TrainDataSing[np.argsort(tstTrialOrder, kind='stable')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], S1TrainDataSingMix, S1TestDataSingMix, \n",
    "                                   lambda_list, 'switch', .2, roiNum, S1RoiMaskSing)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_mix_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_mix_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_mix_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], S2TrainDataSingMix, S2TestDataSingMix, \n",
    "                                   lambda_list, 'switch', .2, roiNum, S2RoiMask)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S2_mix_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S2_mix_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S2_mix_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], S1TrainDataRep, S1TestDataRep, lambda_list, \n",
    "                                        'cross',.2, roiNum, S1RoiMaskRep, S2TrainDataRep, S2TestDataRep, S2RoiMask)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_src_cross_cc.pkl')\n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_src_cross_wts.pkl')\n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_src_cross_lambdas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], S2TrainDataRep, S2TestDataRep, lambda_list, \n",
    "                                        'cross',.2, roiNum, S2RoiMask, S1TrainDataRep,S1TestDataRep, S1RoiMaskRep)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S2_src_cross_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S2_src_cross_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S2_src_cross_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_wts_S1_avg' not in locals():\n",
    "    \n",
    "    print 'Please Load S1 Repeated Trial Vox2Vox Weight Data Frame as df_wts_S1_avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origTrn = np.concatenate([S1TrainDataRep[:,S1RoiMaskRep==1],S1TrainDataRep[:,S1RoiMaskRep==2],\n",
    "                          S1TrainDataRep[:,S1RoiMaskRep==3],S1TrainDataRep[:,S1RoiMaskRep==6],\n",
    "                          S1TrainDataRep[:,S1RoiMaskRep==4],S1TrainDataRep[:,S1RoiMaskRep==7]],axis=1)\n",
    "origTst = np.concatenate([S1TestDataRep[:,S1RoiMaskRep==1],S1TestDataRep[:,S1RoiMaskRep==2],\n",
    "                          S1TestDataRep[:,S1RoiMaskRep==3],S1TestDataRep[:,S1RoiMaskRep==6],\n",
    "                          S1TestDataRep[:,S1RoiMaskRep==4],S1TestDataRep[:,S1RoiMaskRep==7]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'wm'\n",
    "\n",
    "wts = np.concatenate(df_wts_S1_avg.loc[src][:6])\n",
    "predTrnWM = np.dot(S1TrainDataRep[:,S1RoiMaskRep==roiNum[src]], wts.T)\n",
    "predTstWM = np.dot(S1TestDataRep[:,S1RoiMaskRep==roiNum[src]], wts.T)\n",
    "\n",
    "trnAdj = origTrn - predTrnWM\n",
    "tstAdj = origTst - predTstWM\n",
    "\n",
    "roiAdj = np.concatenate([np.repeat(1, (S1RoiMaskRep==1).sum()),np.repeat(2, (S1RoiMaskRep==2).sum()),\n",
    "                         np.repeat(3, (S1RoiMaskRep==3).sum()),np.repeat(6, (S1RoiMaskRep==6).sum()),\n",
    "                         np.repeat(4, (S1RoiMaskRep==4).sum()),np.repeat(7, (S1RoiMaskRep==7).sum())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], trnAdj, tstAdj, lambda_list, 'average', .2, \n",
    "                                        roiNum, roiAdj)\n",
    "\n",
    "df_cc_S1_avg.to_pickle(data_folder + 'results/voxel2voxel/S1_wm_adj_cc.pkl') \n",
    "df_wts_S1_avg.to_pickle(data_folder + 'results/voxel2voxel/S1_wm_adj_wts.pkl')  \n",
    "best_lambs_S1_avg.to_pickle(data_folder + 'results/voxel2voxel/S1_wm_adj_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'air'\n",
    "\n",
    "wts = np.concatenate(df_wts_S1_avg.loc[src][:6])\n",
    "predTrnAir = np.dot(S1TrainDataRep[:,S1RoiMaskRep==roiNum[src]], wts.T)\n",
    "predTstAir = np.dot(S1TestDataRep[:,S1RoiMaskRep==roiNum[src]], wts.T)\n",
    "\n",
    "trnAdj = origTrn - predTrnAir\n",
    "tstAdj = origTst - predTstAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], trnAdj, tstAdj, lambda_list, 'average',.2, \n",
    "                                        roiNum, roiAdj)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_air_adj_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_air_adj_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_air_adj_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnAdj = origTrn - predTrnAir - predTrnWm\n",
    "tstAdj = origTst - predTstAir - predTrnWm\n",
    "\n",
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], trnAdj, tstAdj, lambda_list, 'average', .2, \n",
    "                                        roiNum, roiAdj)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_both_adj_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_both_adj_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_both_adj_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'v1'\n",
    "sn = 1\n",
    "\n",
    "predTrnV1Lat = np.zeros((1750,(S1RoiMaskRep==sn).sum()))\n",
    "predTstV1Lat = np.zeros((120,(S1RoiMaskRep==sn).sum()))\n",
    "for i in range((S1RoiMaskRep==sn).sum()):\n",
    "    \n",
    "    predTrnV1Lat[:,i] = np.dot(np.delete(S1TrainDataRep[:,S1RoiMaskRep==sn],i,axis=1), \n",
    "                               df_wts_S1_avg.loc[src,src][i])\n",
    "    predTstV1Lat[:,i] = np.dot(np.delete(S1TestDataRep[:,S1RoiMaskRep==sn],i,axis=1), \n",
    "                               df_wts_S1_avg.loc[src,src][i])\n",
    "    \n",
    "wts = np.concatenate(df_wts_S1_avg.loc[src][1:6])\n",
    "predTrnV1 = np.dot(S1TrainDataRep[:,S1RoiMaskRep==sn], wts.T)\n",
    "predTstV1 = np.dot(S1TestDataRep[:,S1RoiMaskRep==sn], wts.T)\n",
    "\n",
    "trnAdj = origTrn - np.concatenate([predTrnV1Lat, predTrnV1],axis=1)\n",
    "tstAdj = origTrn - np.concatenate([predTstV1Lat, predTstV1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], trnAdj,tstAdj, lambda_list, 'average', .2, \n",
    "                                        roiNum, roiAdj)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_v1_adj_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_v1_adj_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_v1_adj_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 8470) (120, 8470) (1750, 8470) (120, 8470) (8470,)\n"
     ]
    }
   ],
   "source": [
    "### Subtract fwrf_pred from betas\n",
    "\n",
    "fn = data_folder + '/results/fwRF/dnn_fwrf_Feb-17-2020_1345_repeated_trials_params.h5py'\n",
    "valPred = h5py.File(fn)['val_pred'][:]\n",
    "trnPred = h5py.File(fn)['trn_pred'][:]\n",
    "\n",
    "## fwRF only has ROI voxels to cut down computatational time\n",
    "\n",
    "trnAdj = S1TrainDataRep[:,S1RoiMaskRep>0]\n",
    "tstAdj = S1TestDataRep[:,S1RoiMaskRep>0]\n",
    "trnAdj = trnAdj - trn_pred\n",
    "tstAdj = tstAdj - val_pred\n",
    "roiAdj = S1RoiMaskRep[S1RoiMaskRep>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc, df_wts, best_lambs = v2v.vox2vox(area_list[:6], area_list[:6], trnAdj,tstAdj, lambda_list, 'average', .2, \n",
    "                                        roiNum, roiAdj)\n",
    "\n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_fwrf_adj_cc.pkl') \n",
    "df_wts.to_pickle(data_folder + 'results/voxel2voxel/S1_fwrf_adj_wts.pkl')  \n",
    "best_lambs.to_pickle(data_folder + 'results/voxel2voxel/S1_fwrf_adj_lambdas.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Activity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc = pd.DataFrame(np.nan, index=area_list[:6], columns=area_list[:6],dtype=object)\n",
    "\n",
    "for s, src in enumerate(area_list[:6]):\n",
    "    for t, trg in enumerate(area_list[:6]):\n",
    "        \n",
    "        if s!=t:\n",
    "            \n",
    "            df_cc.loc[src, trg] = v2v.corr2_coeff(np.nanmean(\n",
    "                S1TrainDataRep[:,S1RoiMaskRep==roiNum[src]],axis=1)[:,np.newaxis],\n",
    "                S1TrainDataRep[:,S1RoiMaskRep==roiNum[trg]])\n",
    "            \n",
    "        else:\n",
    "            ccs = np.zeros((S1RoiMaskRep==roiNum[src]).sum())\n",
    "            \n",
    "            for v in range(len(ccs)):\n",
    "                \n",
    "                sv = np.delete(S1TrainDataRep[:,S1RoiMaskRep==roiNum[src]], v, axis=1)\n",
    "                tv = S1TrainDataRep[:,S1RoiMaskRep==roiNum[src]][:,v]\n",
    "                ccs[v]= v2v.sst.pearsonr(np.nanmean(sv, axis=1), tv)[0]\n",
    "            df_cc.loc[src,trg]=ccs\n",
    "        \n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_mean_avg_cc.pkl')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc = pd.DataFrame(np.nan, index=area_list[:6], columns=area_list[:6],dtype=object)\n",
    "\n",
    "for s, src in enumerate(area_list[:6]):\n",
    "    for t, trg in enumerate(area_list[:6]):\n",
    "        \n",
    "        if s!=t:\n",
    "            \n",
    "            df_cc.loc[src, trg] = v2v.corr2_coeff(np.nanmean(\n",
    "                S1TrainDataSing[:,S1RoiMaskSing==roiNum[src]],axis=1)[:,np.newaxis],\n",
    "                S1TrainDataSing[:,S1RoiMaskSing==roiNum[trg]])\n",
    "            \n",
    "        else:\n",
    "            ccs = np.zeros((S1RoiMaskSing==roiNum[src]).sum())\n",
    "            \n",
    "            for v in range(len(ccs)):\n",
    "                \n",
    "                sv = np.delete(S1TrainDataSing[:,S1RoiMaskSing==roiNum[src]], v, axis=1)\n",
    "                tv = S1TrainDataSing[:,S1RoiMaskSing==roiNum[src]][:,v]\n",
    "                ccs[v]= v2v.sst.pearsonr(np.nanmean(sv, axis=1), tv)[0]\n",
    "            df_cc.loc[src,trg]=ccs\n",
    "        \n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S1_mean_single_cc.pkl')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc = pd.DataFrame(np.nan, index=area_list[:6], columns=area_list[:6],dtype=object)\n",
    "\n",
    "for s, src in enumerate(area_list[:6]):\n",
    "    for t, trg in enumerate(area_list[:6]):\n",
    "        \n",
    "        if s!=t:\n",
    "            \n",
    "            df_cc.loc[src, trg] = v2v.corr2_coeff(np.nanmean(\n",
    "                S2TrainDataRep[:,S2RoiMask==roiNum[src]],axis=1)[:,np.newaxis],\n",
    "                S2TrainDataRep[:,S2RoiMask==roiNum[trg]])\n",
    "            \n",
    "        else:\n",
    "            ccs = np.zeros((S2RoiMask==roiNum[src]).sum())\n",
    "            \n",
    "            for v in range(len(ccs)):\n",
    "                \n",
    "                sv = np.delete(S2TrainDataRep[:,S2RoiMask==roiNum[src]], v, axis=1)\n",
    "                tv = S2TrainDataRep[:,S2RoiMask==roiNum[src]][:,v]\n",
    "                ccs[v]= v2v.sst.pearsonr(np.nanmean(sv, axis=1), tv)[0]\n",
    "            df_cc.loc[src,trg]=ccs\n",
    "        \n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S2_mean_avg_cc.pkl')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc = pd.DataFrame(np.nan, index=area_list[:6], columns=area_list[:6],dtype=object)\n",
    "\n",
    "for s, src in enumerate(area_list[:6]):\n",
    "    for t, trg in enumerate(area_list[:6]):\n",
    "        \n",
    "        if s!=t:\n",
    "            \n",
    "            df_cc.loc[src, trg] = v2v.corr2_coeff(np.nanmean(\n",
    "                S2TrainDataSing[:,S2RoiMask==roiNum[src]],axis=1)[:,np.newaxis],\n",
    "                S2TrainDataSing[:,S2RoiMask==roiNum[trg]])\n",
    "            \n",
    "        else:\n",
    "            ccs = np.zeros((S2RoiMask==roiNum[src]).sum())\n",
    "            \n",
    "            for v in range(len(ccs)):\n",
    "                \n",
    "                sv = np.delete(S2TrainDataSing[:,S2RoiMask==roiNum[src]], v, axis=1)\n",
    "                tv = S2TrainDataSing[:,S2RoiMask==roiNum[src]][:,v]\n",
    "                ccs[v]= v2v.sst.pearsonr(np.nanmean(sv, axis=1), tv)[0]\n",
    "            df_cc.loc[src,trg]=ccs\n",
    "        \n",
    "df_cc.to_pickle(data_folder + 'results/voxel2voxel/S2_mean_single_cc.pkl')         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
